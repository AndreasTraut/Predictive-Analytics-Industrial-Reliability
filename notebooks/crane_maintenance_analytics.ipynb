{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a1b2c3d-0001-4000-8000-000000000001",
   "metadata": {},
   "source": [
    "# üèóÔ∏è Crane Predictive Maintenance & Root Cause Analysis\n",
    "\n",
    "This notebook demonstrates **Predictive Maintenance (PdM)** and **Root Cause Analysis (RCA)** on a synthetic crane drive dataset.\n",
    "\n",
    "*Dieses Notebook demonstriert **Predictive Maintenance (PdM)** und **Root Cause Analysis (RCA)** anhand eines synthetischen Kran-Antriebsdatensatzes.*\n",
    "\n",
    "**Data / Daten:** A synthetic dataset that simulates sensor readings from a bridge or tower crane hoist unit, including:\n",
    "- `Load_kg` ‚Äî Current hook load / Aktuelle Last am Haken\n",
    "- `Motor_Temp` ‚Äî Hoist motor temperature / Temperatur des Hubmotors\n",
    "- `Vibration` ‚Äî Vibration at the hoist unit (mm/s) / Schwingung am Hubwerk (mm/s)\n",
    "- `Brake_Wear` ‚Äî Remaining brake pad thickness (mm) / Verbleibende Dicke der Bremsbel√§ge (mm)\n",
    "- `Error_Code` ‚Äî Fault label / Fehlerbezeichnung\n",
    "\n",
    "**Analysis Goals / Analyseziele:**\n",
    "1. **Root Cause Analysis:** Train an XGBoost classifier to predict fault codes from sensor readings.\n",
    "2. **Predictive Maintenance:** Use linear regression to forecast when brake pads will reach the critical threshold of 1.0 mm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1b2c3d-0002-4000-8000-000000000002",
   "metadata": {},
   "source": [
    "### Dataset Generation and Loading / Datensatz-Erzeugung und -Laden\n",
    "\n",
    "This section generates the synthetic crane dataset using the `generate_crane_dataset.py` script and loads it into a pandas DataFrame.\n",
    "\n",
    "*Dieser Abschnitt erzeugt den synthetischen Kran-Datensatz mithilfe des Skripts `generate_crane_dataset.py` und l√§dt ihn in einen pandas DataFrame.*\n",
    "\n",
    "1. **Generate Dataset**: Run the generator script to produce `data/kran_wartung_daten.csv`.\n",
    "2. **Load Dataset**: Read the CSV into a pandas DataFrame.\n",
    "3. **Initial Inspection**: Display shape and first rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b2c3d-0003-4000-8000-000000000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "repo_root = Path(\"..\")\n",
    "csv_path = repo_root / \"data\" / \"kran_wartung_daten.csv\"\n",
    "script_path = repo_root / \"scripts\" / \"generate_crane_dataset.py\"\n",
    "\n",
    "# Generate dataset if it does not exist yet\n",
    "if not csv_path.exists():\n",
    "    result = subprocess.run(\n",
    "        [\"python\", str(script_path), \"--output\", str(csv_path)],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "    )\n",
    "    print(result.stdout or result.stderr)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(csv_path, parse_dates=[\"Timestamp\"])\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1b2c3d-0004-4000-8000-000000000004",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis / Explorative Datenanalyse\n",
    "\n",
    "Describe the dataset statistically and inspect fault class distribution.\n",
    "\n",
    "*Statistische Beschreibung des Datensatzes und √úberblick √ºber die Fehlerklassen-Verteilung.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b2c3d-0005-4000-8000-000000000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistical summary\n",
    "print(\"=== Statistical Summary ===\")\n",
    "display(df.describe())\n",
    "\n",
    "# Fault class distribution\n",
    "print(\"\\n=== Error Code Distribution ===\")\n",
    "print(df[\"Error_Code\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b2c3d-0006-4000-8000-000000000006",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "fig.suptitle(\"Crane Sensor Distributions by Fault Type\", fontsize=14)\n",
    "\n",
    "features = [\"Load_kg\", \"Motor_Temp\", \"Vibration\", \"Brake_Wear\"]\n",
    "for ax, feature in zip(axes.flat, features):\n",
    "    for label, group in df.groupby(\"Error_Code\"):\n",
    "        ax.hist(group[feature], bins=30, alpha=0.5, label=label)\n",
    "    ax.set_title(feature)\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.legend(fontsize=7)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save visualisation\n",
    "viz_path = repo_root / \"docs\" / \"crane_maintenance_insights.png\"\n",
    "plt.savefig(viz_path, dpi=100, bbox_inches=\"tight\")\n",
    "print(f\"‚úÖ Visualization saved to {viz_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1b2c3d-0007-4000-8000-000000000007",
   "metadata": {},
   "source": [
    "### Root Cause Analysis ‚Äî Fault Classification / Fehlerklassifikation\n",
    "\n",
    "Train an **XGBoost** classifier to identify the fault code from sensor readings.\n",
    "\n",
    "*Training eines **XGBoost**-Klassifikators zur Identifikation des Fehlercodes aus Sensordaten.*\n",
    "\n",
    "Pipeline:\n",
    "1. Encode the categorical target `Error_Code` with `LabelEncoder`.\n",
    "2. Scale numeric features with `StandardScaler`.\n",
    "3. 80 / 20 train / test split.\n",
    "4. Fit XGBoost classifier.\n",
    "5. Evaluate with a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b2c3d-0008-4000-8000-000000000008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Feature columns and target\n",
    "feature_cols = [\"Load_kg\", \"Motor_Temp\", \"Vibration\", \"Brake_Wear\"]\n",
    "X = df[feature_cols].copy()\n",
    "y_raw = df[\"Error_Code\"].copy()\n",
    "\n",
    "# Encode target labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_raw)\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train / test split (80 / 20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train XGBoost classifier\n",
    "clf = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    random_state=42,\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "# Use only labels present in the data; zero_division=0 avoids warnings for unseen classes\n",
    "present_labels = sorted(set(y))\n",
    "present_names = [le.classes_[i] for i in present_labels]\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred, labels=present_labels, target_names=present_names, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b2c3d-0009-4000-8000-000000000009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance plot\n",
    "importances = clf.feature_importances_\n",
    "feat_df = pd.DataFrame({\"Feature\": feature_cols, \"Importance\": importances})\n",
    "feat_df = feat_df.sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.barplot(data=feat_df, x=\"Importance\", y=\"Feature\", hue=\"Feature\", palette=\"viridis\", legend=False)\n",
    "plt.title(\"XGBoost Feature Importance ‚Äî Root Cause Analysis\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1b2c3d-000a-4000-8000-00000000000a",
   "metadata": {},
   "source": [
    "### Predictive Maintenance ‚Äî Brake Wear Forecast / Bremsbelag-Verschlei√üvorhersage\n",
    "\n",
    "Use **linear regression** over time to predict when the brake pad thickness (`Brake_Wear`) will reach the critical threshold of **1.0 mm**.\n",
    "\n",
    "*Einsatz von **linearer Regression** √ºber die Zeit zur Vorhersage, wann die Bremsbelagdicke (`Brake_Wear`) den kritischen Grenzwert von **1,0 mm** unterschreitet.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b2c3d-000b-4000-8000-00000000000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Use row index as time proxy (hours since start)\n",
    "hours = np.arange(len(df)).reshape(-1, 1)\n",
    "brake_wear = df[\"Brake_Wear\"].values\n",
    "\n",
    "# Fit linear regression\n",
    "reg = LinearRegression()\n",
    "reg.fit(hours, brake_wear)\n",
    "\n",
    "print(f\"Slope (mm per hour): {reg.coef_[0]:.6f}\")\n",
    "print(f\"Intercept:           {reg.intercept_:.4f}\")\n",
    "\n",
    "# Predict: when does the wear line cross 1.0 mm?\n",
    "# 1.0 = slope * t + intercept  =>  t = (1.0 - intercept) / slope\n",
    "critical_threshold_mm = 1.0\n",
    "t_critical = (critical_threshold_mm - reg.intercept_) / reg.coef_[0]\n",
    "t_critical_date = df[\"Timestamp\"].iloc[0] + pd.Timedelta(hours=t_critical)\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Predicted maintenance date (brake at {critical_threshold_mm} mm):\")\n",
    "print(f\"    {t_critical_date.strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(f\"    (~{int(t_critical - len(df))} hours from last observation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b2c3d-000c-4000-8000-00000000000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise brake wear trend and maintenance prediction\n",
    "future_hours = np.arange(int(t_critical) + 50).reshape(-1, 1)\n",
    "predicted_wear = reg.predict(future_hours)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df[\"Timestamp\"], brake_wear, label=\"Measured Brake Wear\", alpha=0.7)\n",
    "future_timestamps = [\n",
    "    df[\"Timestamp\"].iloc[0] + pd.Timedelta(hours=int(h)) for h in future_hours.flatten()\n",
    "]\n",
    "plt.plot(future_timestamps, predicted_wear, \"--\", color=\"orange\", label=\"Linear Trend\")\n",
    "plt.axhline(y=critical_threshold_mm, color=\"red\", linestyle=\":\", label=f\"Critical: {critical_threshold_mm} mm\")\n",
    "plt.axvline(x=t_critical_date, color=\"red\", linestyle=\"--\", alpha=0.6, label=f\"Maintenance due: {t_critical_date.strftime('%Y-%m-%d')}\")\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Brake Wear (mm)\")\n",
    "plt.title(\"Predictive Maintenance ‚Äî Brake Pad Wear Forecast\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
