{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "874775ee",
      "metadata": {
        "id": "874775ee"
      },
      "source": [
        "# Flight Delay Prediction\n",
        "\n",
        "This notebook processes flight data from 2024 to predict flight delays.\n",
        "\n",
        "**Data:** The dataset contains information about various flights, including:\n",
        "*   Flight dates (year, month, day of week)\n",
        "*   Carrier information (unique carrier, flight number)\n",
        "*   Origin and destination airports\n",
        "*   Departure and arrival delays\n",
        "*   Flight distance\n",
        "*   Cancellation and diversion status\n",
        "\n",
        "**Prediction Goal:** The primary objective is to predict whether a flight will be 'Delayed'. A flight is classified as 'Delayed' if its arrival delay (`arr_delay`) is greater than 15 minutes. This is a binary classification problem."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d160f764",
      "metadata": {
        "id": "d160f764"
      },
      "source": [
        "### Data Loading and Target Creation\n",
        "\n",
        "This section handles the initial loading of the flight data from a CSV file. It performs the following steps:\n",
        "\n",
        "1.  **Load Dataset**: Reads the `flight_data_2024.csv` file into a pandas DataFrame.\n",
        "2.  **Create Target Variable**: A new column named `Delayed` is created. A flight is considered 'Delayed' if its arrival delay (`arr_delay`) is greater than 15 minutes. This is a binary classification target (1 for delayed, 0 for not delayed).\n",
        "3.  **Select Relevant Columns**: Keeps only the columns necessary for the analysis and model training, discarding irrelevant ones.\n",
        "4.  **Save to Database**: The processed DataFrame is then saved into a SQLite database named `flights2024.db` as a table called `flights2024`. This step ensures that the data is persistently stored and can be easily queried later."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6910028",
      "metadata": {
        "id": "c6910028"
      },
      "source": [
        "Loading the CSV file and creating a target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "09cce119",
      "metadata": {
        "id": "09cce119",
        "outputId": "795c5263-9835-47e5-90c7-90cfe5f778c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_22332\\2398628157.py:17: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(csv_path)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Robust CSV loading: prefer full dataset, fall back to sample, else instruct user\n",
        "csv_path = Path(\"../data/flight_data_2024.csv\")\n",
        "if not csv_path.exists():\n",
        "    sample_path = csv_path.with_name(\"flight_data_2024_sample.csv\")\n",
        "    if sample_path.exists():\n",
        "        print(\"Full dataset not found — using sample dataset at: {}\".format(sample_path))\n",
        "        csv_path = sample_path\n",
        "    else:\n",
        "        raise FileNotFoundError(\"Dataset not found. Please run 'dvc pull' or place 'flight_data_2024.csv' in the project 'data/' folder.\")\n",
        "\n",
        "# Load dataset (either full or sample)\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# ✅ Use lowercase column name 'arr_delay'\n",
        "df[\"Delayed\"] = (df[\"arr_delay\"] > 15).astype(int)\n",
        "\n",
        "# Keep relevant columns\n",
        "df = df[[\n",
        "    \"year\", \"month\", \"day_of_week\", \"fl_date\",\n",
        "    \"op_unique_carrier\", \"op_carrier_fl_num\",\n",
        "    \"origin\", \"dest\", \"dep_delay\", \"arr_delay\",\n",
        "    \"distance\", \"cancelled\", \"diverted\", \"Delayed\"\n",
        "]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c0c54ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Save to DB\n",
        "engine = create_engine(\"sqlite:///flights2024.db\")\n",
        "df.to_sql(\"flights2024\", con=engine, if_exists=\"replace\", index=False)\n",
        "\n",
        "print(\"✅ flights2024 table created successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "674d8ee6",
      "metadata": {
        "id": "674d8ee6"
      },
      "source": [
        "### Data Querying and Preprocessing\n",
        "\n",
        "This section prepares the data for model training by querying the necessary features from the database and applying preprocessing steps:\n",
        "\n",
        "1.  **Query Data**: Selects relevant features from the `flights2024` table, specifically filtering out cancelled and diverted flights, as these might be handled separately or are not suitable for predicting typical delays.\n",
        "2.  **Encode Categorical Features**: Categorical columns like `op_unique_carrier`, `origin`, and `dest` are converted into numerical representations using `LabelEncoder`. This is necessary because machine learning models typically require numerical input.\n",
        "3.  **Feature and Target Split**: The dataset is divided into features (`X`) and the target variable (`y`, which is 'Delayed').\n",
        "4.  **Train/Test Split**: The data is further split into training and testing sets (`X_train`, `X_test`, `y_train`, `y_test`) using `train_test_split`. This allows the model to be trained on one portion of the data and evaluated on unseen data to assess its generalization performance. `stratify=y` ensures that the proportion of delayed vs. non-delayed flights is maintained in both sets.\n",
        "5.  **Scale Numeric Features**: Numerical features in `X_train` and `X_test` are scaled using `StandardScaler`. This standardizes the features by removing the mean and scaling to unit variance, which can help improve the performance and convergence of some machine learning algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dacd450",
      "metadata": {
        "id": "3dacd450"
      },
      "source": [
        "Quering and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21454fb1",
      "metadata": {
        "id": "21454fb1"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "query = \"\"\"\n",
        "SELECT year, month, day_of_week, dep_delay, distance,\n",
        "       op_unique_carrier, origin, dest, cancelled, diverted, Delayed\n",
        "FROM flights2024\n",
        "WHERE cancelled = 0 AND diverted = 0\n",
        "\"\"\"\n",
        "df = pd.read_sql(query, engine)\n",
        "\n",
        "# Encode categorical columns\n",
        "for col in [\"op_unique_carrier\", \"origin\", \"dest\"]:\n",
        "    df[col] = LabelEncoder().fit_transform(df[col])\n",
        "\n",
        "X = df.drop(\"Delayed\", axis=1)\n",
        "y = df[\"Delayed\"]\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Scale numeric features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ecc0c70",
      "metadata": {
        "id": "4ecc0c70"
      },
      "source": [
        "### Model Training and Evaluation\n",
        "\n",
        "This section involves training a machine learning model and assessing its performance:\n",
        "\n",
        "1.  **Initialize XGBoost Classifier**: An `XGBClassifier` is initialized with specific hyperparameters (`n_estimators`, `max_depth`, `learning_rate`, `random_state`, `n_jobs`). XGBoost is a powerful gradient boosting framework known for its efficiency and performance.\n",
        "2.  **Train Model**: The model is trained using the preprocessed training data (`X_train`, `y_train`).\n",
        "3.  **Make Predictions**: Once trained, the model makes predictions on the unseen test data (`X_test`).\n",
        "4.  **Evaluate Performance**: The model's performance is evaluated using common classification metrics:\n",
        "    *   **Accuracy Score**: The proportion of correctly classified instances.\n",
        "    *   **Classification Report**: Provides a detailed breakdown of precision, recall, and f1-score for each class (delayed vs. not delayed), along with support (the number of actual occurrences of each class in the specified dataset)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb0f44a0",
      "metadata": {
        "id": "eb0f44a0"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dde5e9aa",
      "metadata": {
        "id": "dde5e9aa",
        "outputId": "f4f99e71-7206-4307-da6f-57ecac8da50d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Accuracy: 0.9326932050013854\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96   1112376\n",
            "           1       0.92      0.73      0.81    280678\n",
            "\n",
            "    accuracy                           0.93   1393054\n",
            "   macro avg       0.93      0.86      0.89   1393054\n",
            "weighted avg       0.93      0.93      0.93   1393054\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"✅ Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70ab25c2",
      "metadata": {
        "id": "70ab25c2"
      },
      "source": [
        "### Save Predictions\n",
        "\n",
        "This final section uses the trained model to make predictions on the entire dataset and saves the results:\n",
        "\n",
        "1.  **Predict on Full Dataset**: The trained model makes predictions (`Predicted`) on the complete, scaled dataset (`X_full`).\n",
        "2.  **Store Predictions**: The `Predicted` column is added back to the original DataFrame `df` (which now contains the preprocessed features).\n",
        "3.  **Save to Database**: The DataFrame, now including the predictions, is saved to the SQLite database `flights2024.db` as a new table named `flight_preds_2024`. This allows for easy access and analysis of the predictions alongside the original data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82bcd9c3",
      "metadata": {
        "id": "82bcd9c3"
      },
      "source": [
        "Save Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c0f5c6d",
      "metadata": {
        "id": "8c0f5c6d",
        "outputId": "bfa4e1cd-2330-4770-fb30-003521ec8836"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Predictions saved to flight_preds_2024 table\n"
          ]
        }
      ],
      "source": [
        "# Predict on full dataset\n",
        "X_full = scaler.transform(X)\n",
        "df[\"Predicted\"] = model.predict(X_full)\n",
        "\n",
        "df.to_sql(\"flight_preds_2024\", con=engine, if_exists=\"replace\", index=False)\n",
        "\n",
        "print(\"✅ Predictions saved to flight_preds_2024 table\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.9.5)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
